<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Text analysis | Discussions on r/politics</title><script src=https://cdn.tailwindcss.com></script><script src=https://unpkg.com/feather-icons></script><script src=https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js></script><script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script><style type=text/tailwindcss>
    @layer base {
        body {
          @apply bg-gray-100;
          @apply font-sans;
          @apply leading-normal;
          @apply tracking-normal;
        }
        p {
          @apply py-6;
        }
        a {
          @apply text-green-500;
          @apply no-underline;
          @apply hover:underline;
        }
        h1 {
          @apply py-2;
          @apply font-sans;
          @apply text-2xl;
        }
        h2 {
          @apply py-2;
          @apply font-sans;
          @apply text-xl;
        }
        h3 {
          @apply py-2;
          @apply font-sans;
          @apply text-lg;
        }
        ol {
          @apply px-8;
          @apply list-decimal;
        }
        ul {
          @apply px-8;
          @apply list-disc;
        }
        blockquote {
          @apply border-l-4; 
          @apply border-green-500;
          @apply italic;
          @apply my-8;
          @apply pl-8;
          @apply md:pl-12;
        }
        pre {
          @apply bg-gray-900;
          @apply rounded;
          @apply text-white; 
          @apply font-mono;
          @apply text-base;
          @apply my-4;
          @apply p-2;
          @apply md:p-4;
        }
        table {
          @apply shadow-md;
          @apply rounded-lg;
          @apply m-auto;
          @apply my-8;
        }
        thead {
          @apply bg-gray-50;
        }
        th {
          @apply py-3;
          @apply px-6;
          @apply text-xs;
          @apply font-medium;
          @apply tracking-wider;
          @apply text-left;
          @apply text-gray-700;
          @apply uppercase;
        }
        tr {
          @apply bg-white;
          @apply border-b;
        }
        td {
          @apply py-4;
          @apply px-6;
          @apply text-sm;
          @apply font-medium;
          @apply text-gray-900;
          @apply whitespace-nowrap;
        }
        img {
          @apply m-auto;
          @apply object-cover;
        }
        .footer-icon {
          width: 64px; 
          height: 64px;
          @apply mx-4;
        }
      }
    </style></head><body><nav id=header class="fixed w-full z-10 top-0"><div id=progress class="h-1 z-20 top-0" style="background:linear-gradient(to right,#4dc0b5 var(--scroll),transparent 0)"></div><div class="w-full md:max-w-4xl mx-auto flex flex-wrap items-center justify-between mt-0 py-3"><div class=pl-4><a class="text-gray-900 text-base no-underline hover:no-underline font-extrabold text-xl" href=https://lassesofus.github.io/Political_discussions/>Discussions on r/politics</a></div><div class="block lg:hidden pr-4"><button id=nav-toggle class="flex items-center px-3 py-2 border rounded text-gray-900 border-gray-600 hover:text-gray-900 hover:border-green-500 appearance-none focus:outline-none"><svg class="fill-current h-3 w-3" viewBox="0 0 20 20" xmlns="http://www.w3.org/2000/svg"><title>Menu</title><path d="M0 3h20v2H0V3zm0 6h20v2H0V9zm0 6h20v2H0v-2z"/></svg></button></div><div class="w-full flex-grow lg:flex lg:items-center lg:w-auto hidden lg:block mt-2 lg:mt-0 bg-gray-100 md:bg-transparent z-20" id=nav-content><ul class="list-reset lg:flex justify-end flex-1 items-center list-none px-0"><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../data-description>Data</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../text-analysis>Text</a></li><li><a class="inline-block py-2 px-4 text-gray-900 no-underline" href=../network-analysis>Network</a></li></ul></div></div></nav><div class="container w-full md:max-w-3xl mx-auto pt-20"><div class="w-full px-4 md:px-6 text-xl text-gray-800 leading-normal" style=font-family:Georgia,serif><div class=font-sans><h1 class="font-bold font-sans break-normal text-gray-900 pt-6 pb-2 text-3xl md:text-4xl">Text analysis</h1></div><p>The U.S. elections are one of the most observed international events, as they affect and influence different countries’ policy-making approaches and economies. Hence, various hidden aspects of elections are drawn out and analyzed using sentiment analysis, but it also has limitations; for example, it is hard to recognize sarcasm trivially. In some cases, the negative sentiments are classified as positive due to the writing styles employed. Note, the project does not cover these shortcomings.</p><h2 id=word-clouds>Word clouds</h2><p>Social media might not represent complete sentiment in elections, since all voters are not present, but provides a sample space of people&rsquo;s opinions. One way of interpreting the texts left by users is by word clouds; a graphical representation of the term frequency - inverse document frequencies (<a href=https://www.wikiwand.com/en/Tf%E2%80%93idf>TF-IDF</a>). This gives greater prominence to words appearing frequently in the source text, ie. larger words are most impactful. By aggregating the comments based on &lsquo;Trump&rsquo; or &lsquo;Biden&rsquo; and tokenizing, the following two word clouds were generated:</p><table><thead><tr><th style=text-align:center>Trump</th><th style=text-align:center>Biden</th></tr></thead><tbody><tr><td style=text-align:center><img src=../images/WordCloud_Trump.png alt=alt></td><td style=text-align:center><img src=../images/WordCloud_Biden.png alt=alt></td></tr></tbody></table><p>Generally, the results show the same words with varying degrees of importance. Due to the likeness the scope of possible analysis is limited. Noteworthy differences may include &ldquo;vote&rdquo;, &ldquo;president&rdquo;, and &ldquo;covid&rdquo;. The latter might be due to the inherent criticism of the Trump administration&rsquo;s response to Covid-19, one of the primary talking points of the election.</p><p>The word clouds, while being a lens into the vocabulary of writers on Reddit, does not yield distinctive enough of an analysis to draw out anything of major value. Hence, the following carries into the dictionary based methods.</p><h2 id=sentiment-analysis>Sentiment analysis</h2><p>Investigating the evolution of the sentiments over the course of the election seems a natural extension to the analysis. Aggregating the comments dataset mitigates contextual issues, because there is generally more consistency in how positive and negative words are used in longer texts, which is verified by the rule-of-thumb of 10.000 tokens for each document and can be seen below:</p><p><img src=../images/DailyDoc.png alt>
<em>The daily aggregated number of tokens for the comments in the collected dataset.</em></p><p>The dip in the tail of this histogram is represented in the days following the election, of which the total daily length of comments on the submissions drastically fell off. Overall, it seems reasonable to continue conducting the analysis disregarding the final three days of 2020-11-04 till 2020-11-07.</p><p>Using the <a href=https://hedonometer.org/words/labMT-en-v1/>Hedonometer</a><sup id=fnref:1><a href=#fn:1 class=footnote-ref role=doc-noteref>1</a></sup>, or labMT lexicon, is a general purpose sentiment dictionary assembled by the Computational Story Lab at the University of Vermont. It was constructed by taking the 5,000 most frequently used words from Twitter, New York Times, Google Books, and music lyrics. In total, there are 10,022 words. Words were rated on a continuous scale from 1 to 9 by crowd workers on Amazon Mechanical Turk, where 1 is the least happy and 9 is the most. The average happiness of each token in the daily documents of Joe Biden and Donald Trump were computed:</p><p><img src=../images/Avghscore.png alt>
<em>Average sentiment expressed in comments on r/politics for the two presidential candidates.</em></p><p>Comments pertaining to Biden indeed fluctuate more compared to his counterpart, which seems pretty stable around 5.5, the latter accounted for due to the 4:1 ratio of Trump vs. Biden comments. On the election day, both candidates seem to drop based off of the Reddit comments. This might be partially due to the oppositions scolding the results, and in turn the respective candidate, as it is rarely unknown who will win before the last vote is counted.</p><p><img src=../images/polling_data.svg alt>
<em>Polling data as presented in the Data section.</em></p><p>Based on the polling data presented previouosly, there is an indication of Biden&rsquo;s higher happiness score correlating with more votes. One may also believe, that if the general populace opinion of a candidate is positive, it will reflect in the amount of people voting for them.</p><h2 id=shifts-on-election-day>Shifts on election day</h2><p>The shifterator package allows for visualizing pairwise comparisons between texts by word shifts, extracting the essence difference and how they do so. Here, the idea is to compare the sentiments of comments on election day with the 33 preceding days'. The following plot has been made:</p><p><img src=../images/shifteratorGraph.svg alt>
<em>Investigating the words that caused the largest change in the sentiment on 11-03-2020 compared to the preceding weeks.</em></p><p>Inspecting the results, the primary difference of sentiments across time span between the two documents centres itself around crime, protests, the Covid-19 pandemic, and monetary problems such as taxes. Most noticeably, there is a trend towards a more negative sentiment on election day than previously. Many Trump-supporters were on the streets and harassed the vote counting offices, so it is not a surprise that these words occur in a more negative light, as the losing side tried to stamp the election as fraudulent.</p><h2 id=partitioning-redditors-based-on-comments>Partitioning redditors based on comments</h2><p>To create a binary partitioning of the redditors active on r/politics in the objective period, we simply concatenated all the comments relating to Trump and Biden respectively for each redditor and calculated a compound sentiment score for each group of joined comments using the VADER module from the nltk.sentiment library. Whichever group of comments had a higher sentiment score would determine the inferred political conviction of the redditor. The Valence Aware Dictionary and sEntiment Reasoner (VADER) module has been specifically created to work with text produced on social media. One of the great features of this module is that it is quite robust in terms of the needed data cleaning and processing to function properly. Typical processing steps like tokenization and stemming as well as removing stop words are consequently not required to have the VADER module work well and provide an indication of the sentiment of a body of text.</p><p>Having come up with a rather naïve inference of the political conviction of the redditors, the binary partitioning was made simply by dividing the redditors on this computed <em>conviction</em> attribute. This partitioning had 64 % inferred Biden supporters and 36% inferred Trump supporters, which would be used in our network analysis.</p><section class=footnotes role=doc-endnotes><hr><ol><li id=fn:1 role=doc-endnote><p><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0029484">Positivity of the English language</a>&#160;<a href=#fnref:1 class=footnote-backref role=doc-backlink>&#8617;&#xfe0e;</a></p></li></ol></section><hr class="border-b-2 border-gray-400 mt-8 mx-4"><div class="font-sans flex justify-between content-center px-4 pb-12"><div class=text-left><p><a href=../data-description class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">&lt;
Previous Page</a></p></div><div class=text-right><p><a href=../network-analysis class="break-normal text-base md:text-sm text-green-500 font-bold no-underline hover:underline">Next
Page ></a></p></div></div></div></div><footer class="bg-white border-t border-gray-400 shadow"><div class="container max-w-4xl mx-auto flex py-8"><div class="w-full mx-auto flex flex-col"><div class="flex w-full"><div class="px-8 mx-auto"><ul class="pt-3 list-none px-0 flex"><li><a class="text-gray-600 no-underline py-2" href=../explainer-notebook.html><i data-feather=file-text class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href=https://github.com/JaQtae/SocInfo2022/tree/FinalProject><i data-feather=github class=footer-icon></i></a></li><li><a class="text-gray-600 no-underline py-2" href="https://drive.google.com/drive/folders/1UvzNpKcS7egE62V3mgZRvvcwSYdKZTii?usp=sharing"><i data-feather=hard-drive class=footer-icon></i></a></li></ul></div></div><div class="w-full mx-auto text-center"><ul class="list-reset items-center text-md py-6 list-none flex"><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Alexander Valentini</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Jakob Engel Ketmig</p></li><li class=mx-auto><p class="inline-block text-gray-600 mx-4 font-semibold capitalized">Lasse Møller Sørensen</p></li></ul></div></div></div></footer><script>var h=document.documentElement,b=document.body,st='scrollTop',sh='scrollHeight',progress=document.querySelector('#progress'),scrollpos=window.scrollY,header=document.getElementById("header"),navcontent=document.getElementById("nav-content"),scroll;document.addEventListener('scroll',function(){scroll=(h[st]||b[st])/((h[sh]||b[sh])-h.clientHeight)*100,progress.style.setProperty('--scroll',scroll+'%'),scrollpos=window.scrollY,scrollpos>10?(header.classList.add("bg-white"),header.classList.add("shadow"),navcontent.classList.remove("bg-gray-100"),navcontent.classList.add("bg-white")):(header.classList.remove("bg-white"),header.classList.remove("shadow"),navcontent.classList.remove("bg-white"),navcontent.classList.add("bg-gray-100"))}),document.getElementById('nav-toggle').onclick=function(){document.getElementById("nav-content").classList.toggle("hidden")},feather.replace()</script></body></html>